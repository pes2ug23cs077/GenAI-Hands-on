{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8D2sdzu5RFg",
        "outputId": "af3101a6-5e3c-48fa-b60f-f7c51e85ee31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install groq python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF03c0bmjc0Z",
        "outputId": "ca77158a-21c1-4473-8489-27a016fde9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GROQ API Key: ··········\n",
            "Ask something: I was charged twice for my subscription\n",
            "[Router Decision]: billing\n",
            "\n",
            "Assistant: I'm so sorry to hear that you were charged twice for your subscription. I can imagine how frustrating that must be for you. I'm here to help resolve this issue as quickly as possible.\n",
            "\n",
            "To start, I'd like to apologize for the error and assure you that we'll do our best to correct it. Our policy is to ensure that our customers are only charged once for their subscription, and it's clear that we fell short of that standard in your case.\n",
            "\n",
            "To proceed, I'll need to investigate this further and verify the duplicate charge. Could you please provide me with your subscription details, including your account name and the dates of the duplicate charges? This will help me to look into the matter and determine the best course of action.\n",
            "\n",
            "Once I've verified the duplicate charge, I'll be happy to process a refund for the incorrect charge. Please note that our refund policy typically takes 3-5 business days to process, but I'll do my best to expedite the refund as soon as possible.\n",
            "\n",
            "In the meantime, I want to assure you that we're taking steps to prevent this type of error from happening again in the future. We value your business and appreciate your patience and understanding as we work to resolve this issue.\n",
            "\n",
            "If you have any questions or concerns, please don't hesitate to reach out to me directly. I'm here to help and want to ensure that you're completely satisfied with the resolution. How would you like to proceed, and is there anything else I can assist you with today?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from getpass import getpass\n",
        "\n",
        "# Securely ask for API key (only if not already set)\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "if not api_key:\n",
        "    api_key = getpass(\"Enter your GROQ API Key: \")\n",
        "\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a senior software engineer. \"\n",
        "            \"Be precise, technical, and solution-oriented. \"\n",
        "            \"Provide code examples when helpful.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a customer billing specialist. \"\n",
        "            \"Be empathetic, polite, and policy-driven. \"\n",
        "            \"Clearly explain refund policies and next steps.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": (\n",
        "            \"You are a helpful customer support assistant. \"\n",
        "            \"Respond conversationally and clearly.\"\n",
        "        ),\n",
        "        \"temperature\": 0.7,\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def route_prompt(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Classifies the user query into one category:\n",
        "    technical, billing, general, tool\n",
        "    Returns ONLY the category name.\n",
        "    \"\"\"\n",
        "\n",
        "    routing_prompt = \"\"\"\n",
        "    Classify the following text into one of these categories:\n",
        "    [technical, billing, general, tool]\n",
        "\n",
        "    - technical: programming, bugs, errors, code issues\n",
        "    - billing: payments, refunds, subscriptions, charges\n",
        "    - tool: requests for real-time data (e.g., price of Bitcoin)\n",
        "    - general: casual chat or other inquiries\n",
        "\n",
        "    Return ONLY the category name.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": routing_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "    return category\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fetch_bitcoin_price():\n",
        "    \"\"\"\n",
        "    Mock function to simulate tool usage.\n",
        "    Replace with real API call if needed.\n",
        "    \"\"\"\n",
        "    return \"The current price of Bitcoin is $51,240 (mock data).\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_request(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    1. Routes user input\n",
        "    2. Selects correct expert\n",
        "    3. Calls model OR tool\n",
        "    4. Returns final response\n",
        "    \"\"\"\n",
        "\n",
        "    category = route_prompt(user_input)\n",
        "    print(f\"[Router Decision]: {category}\")\n",
        "\n",
        "    # Tool handling\n",
        "    if category == \"tool\":\n",
        "        return fetch_bitcoin_price()\n",
        "\n",
        "    # Fallback safety\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    config = MODEL_CONFIG[category]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=config[\"temperature\"],\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": config[\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "user_query = input(\"Ask something: \")\n",
        "answer = process_request(user_query)\n",
        "print(\"\\nAssistant:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qhIiyOPmpfhf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYpFmdb6q9cG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
